\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{Concetti preliminari}
\epigraph{Sotto il teorema di Bayes, nessuna teoria è perfetta. Piuttosto, è un lavoro in corso, sempre soggetto a ulteriori perfezionamenti e prove.}{\textit{Nate Silver}}
\hfill \break
La statistica bayesiana è un sottocampo della statistica in cui la verità di un enunciato è espressa in termini di credibilità (\textit{belief})
o più specificatamente di \textbf{probabilità bayesiana}.
\begin{definition}[Probabilità bayesiana]
    \label{def:probabilita_bayesiana}
    La probabilità bayesiana è un'interpretazione del concetto di probabilità, in cui, anziché la frequenza di un qualche evento, la probabilità
    viene vista come aspettativa razionale che rappresenta un stato di conoscenza o come quantificazione di una convinzione personale.
\end{definition}
\hfill \break
Nella visione bayesiana assegniamo una probabilità ad un'ipotesi, che è la probabilità che l'ipotesi sia vera.
Nell' approccio frequentista invece, l'ipotesi viene solo verificata senza che le venga assegnata una probabilità.
Per valutare la probabilità di un'ipotesi si deve fornire una \textbf{probabilità iniziale}(\textit{probabilità a priori}).
Questa a sua volta viene aggiornata con l'arrivo di nuovi dati, che vengono utilizzati per calcolare la \textbf{probabilità aggiornata}(\textit{probabilità a posteriori}),
utilizzando la \textbf{regola di Bayes}.
\begin{definition}[Inferenza bayesiana]
    \label{def:inferenza_bayesiana}
    L'inferenza bayesiana è un approccio alla statistica che utilizza la regola di Bayes per aggiornare la probabilità iniziale con l'arrivo di nuovi dati.
\end{definition}
\hfill \break
Più in generale, possiamo derivare dei metodi di analisi dei dati detti \textbf{metodi bayesiana}, che forniscono:
\begin{itemize}
    \item stima dei parametri con buone proprietà statistiche;
    \item descrizione parsimoniosa dei dati osservati;
    \item previsione di dati mancanti e di dati futuri;
    \item una struttura computazionale (\textit{computational framework}) per la stima, selezione e validazione per i modelli.
\end{itemize}
\section{Apprendimento bayesiano}
L'induzione statistica è un processo che consente di apprendere le caratteristiche generali di una popolazione a partire da un sottoinsieme di essa, ossia da un campione.
I valori numerici delle caratteristiche di una popolazione sono espressi in termini di parametri $\theta$, e le descrizioni numeriche del sottoinsieme forma il dataset $y$.
Prima che venga ottenuto il dataset, i valori numerici sia delle caratteristiche della popolazione che del dataset sono incerti. Dopo che un dataset $y$ è stato ottenuto,
L'informazione contenuta nel dataset può essere utilizzata per ridurre la nostra incertezza sulle caratteristiche della popolazione, cioè su $\theta$.
Quantificare questo cambiamento di incertezza è il compito dell'inferenza bayesiana.
I nostri spazi sono:
\begin{itemize}
    \item $\mathcal{Y}$: spazio del campione;
    \item $\Theta$: spazio dei parametri;
\end{itemize}
Lo spazio del campione è l'insieme di tutti i possibili dataset a cui appartiene un singolo dataset $y$.
Lo spazio dei parametri è l'insieme di tutti i possibili valori dei parametri $\theta$, da cui speriamo di identificare il valore che meglio descrive la popolazione.
\hfill \break
L'apprendimento bayesiano inizia con una formulazione numerica della probabilità congiunta di $y$ e $\theta$, espressi in termini di distribuzione di probabilità su $\mathcal{Y}$
e $\Theta$.
In soldoni, la probabilità congiunta è la probabilità che $y$ e $\theta$ si verifichino contemporaneamente.
A questo punto inizia il processo ricorsivo:
\begin{enumerate}
    \item Per ogni valore numerico $\theta \in \Theta$, la nostra \textbf{distribuzione iniziale} $p(\theta)$ descrive la nostra convinzione iniziale che $\theta$ rappresenti le vere caratteristiche della popolazione.
    \item Per ogni $\theta \in \Theta$ e $y \in \mathcal{Y}$, il nostro \textbf{modello campionario} $p(y|\theta)$ descrive la nostra convinzione che $y$ sia il risultato del nostro studio sapendo che $\theta$ è vero.
    \item Per ogni valore numerico $\theta \in \Theta$, la nostra \textbf{distribuzione a posteriori} $p(\theta|y)$ descrive la nostra convinzione che $\theta$ rappresenti le vere caratteristiche della popolazione sapendo avendo osservato $y$.
\end{enumerate}
La distribuzione a posteriore è ottenuta dalla distribuzione iniziale e dal modello campionario, tramite la \textbf{regola di Bayes} (che vedremo successivamente).
\begin{remark}
    È importante notare che la regola di Bayes non indica come dovrebbero essere le nostre convinzioni, ma come dovrebbero cambiare con l'arrivo di nuove informazioni.
\end{remark}
\end{document}